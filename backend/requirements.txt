flask==3.0.0
yt-dlp==2023.12.30
youtube-transcript-api==1.2.3
openai-whisper==20231117
openai==1.54.0
anthropic==0.39.0

# ================================
# PyTorch - CPU-only version
# ================================
# Using CPU-only PyTorch to optimize for:
# - Fast deployments (2-3 min vs 10-15 min with GPU libs)
# - Low disk usage (200 MB vs 2.5 GB with CUDA/cuDNN)
# - Render free/standard tier has no GPU anyway
#
# Performance: NO CHANGE (already CPU-bound)
# - 10-min video: ~30-45 seconds transcription time
#
# When to switch to GPU version:
# - Processing 500+ videos/day
# - Moving to GPU-enabled hosting (AWS/GCP)
# - Revenue justifies $250-400/month GPU costs
#
# How to switch back to GPU:
# 1. Remove the --extra-index-url line below
# 2. Change torch==2.2.0+cpu to torch==2.2.0
# 3. Deploy to GPU-enabled infrastructure
#
# See README.md "Infrastructure & Performance Notes" for details
# ================================
--extra-index-url https://download.pytorch.org/whl/cpu
torch==2.2.0+cpu

numpy<2.0
stripe==7.7.0
supabase==2.10.0
python-dotenv==1.0.0
pyjwt==2.8.0
gunicorn==21.2.0
reportlab==4.0.7
python-docx==1.1.0
requests==2.31.0

